# [Project Name] Research Findings

**Research Plan**: See `memory/research-plans/[project-name]-research-plan.md`

**Date**: [Date]

**Research Lead**: [Name]

**Sessions Conducted**: [Number] participants (P01-P[##])

---

## Executive Summary

[Top 3-5 findings in bullet format - each should be actionable and specific]

1. **[Key Finding 1]** - [One sentence with impact]
2. **[Key Finding 2]** - [One sentence with impact]
3. **[Key Finding 3]** - [One sentence with impact]
4. **[Key Finding 4]** - [One sentence with impact]
5. **[Key Finding 5]** - [One sentence with impact]

---

## Research Goals Recap

**Original research questions**:
1. [Question from research plan]
2. [Question from research plan]
3. [Question from research plan]

**Hypothesis**: [State the hypothesis from research plan]

---

## Hypothesis Validation

**Result**: âœ… Supported / âŒ Refuted / ğŸŸ¡ Partially Supported / â“ Inconclusive

**Evidence Summary**:
[2-3 sentences explaining whether the data supports or refutes the hypothesis]

**Implications**:
- **If supported**: [What this means for product/design decisions]
- **If refuted**: [What alternative direction this suggests]
- **If partial**: [What's supported, what isn't, and what needs more research]

---

## Top Pain Points

*Pain points are ranked by severity and frequency. Each includes evidence from participant transcripts.*

---

### Pain Point 1: [Clear, specific description]

**Description**: [2-3 sentences explaining the pain point in detail]

**Evidence from Participants**:
- **P01** (12:34): "[Exact quote showing this pain point]"
- **P03** (08:15): "[Exact quote]"
- **P05** (15:42): "[Exact quote]"

**Frequency**: [X]/[Total] participants mentioned this ([X]%)

**Severity**: ğŸ”´ High / ğŸŸ¡ Medium / ğŸŸ¢ Low

**Context**: [When/where does this pain point occur? What triggers it?]

**Affected Product Area**: [Feature / Workflow / Screen name]

**Impact on User Experience**:
- [Specific impact - e.g., "Blocks task completion"]
- [Specific impact - e.g., "Causes frustration and abandonment"]
- [Specific impact - e.g., "Increases time-on-task by estimated X minutes"]

**User Behavior Observed**:
- [What users did when encountering this pain point]
- [Workarounds they attempted]
- [Error patterns]

---

### Opportunity: [What could be improved for Pain Point 1]

**Recommendation**: [Specific, actionable recommendation]

**Expected Impact**: [What would improve if this were addressed]
- [Metric or outcome]
- [User benefit]

**Priority**: ğŸ”´ High / ğŸŸ¡ Medium / ğŸŸ¢ Low

**Rationale**: [Why this priority - consider: frequency, severity, business impact, feasibility]

---

### Pain Point 2: [Description]

**Description**: [...]

**Evidence from Participants**:
- **P02** (10:23): "[Quote]"
- **P04** (14:56): "[Quote]"

**Frequency**: [X]/[Total] participants ([X]%)

**Severity**: ğŸ”´ High / ğŸŸ¡ Medium / ğŸŸ¢ Low

**Context**: [...]

**Affected Product Area**: [...]

**Impact on User Experience**:
- [...]

---

### Opportunity: [What could be improved for Pain Point 2]

**Recommendation**: [...]

**Expected Impact**: [...]

**Priority**: ğŸ”´ High / ğŸŸ¡ Medium / ğŸŸ¢ Low

---

### Pain Point 3: [Description]

*[Continue format for all pain points - typically 5-10 total]*

---

## Theme Analysis

*High-level patterns across pain points*

| Theme | Description | Pain Points Included | Participant Frequency | Priority |
|-------|-------------|---------------------|----------------------|----------|
| [Theme 1] | [What this theme represents] | PP1, PP3, PP5 | [X]/[Total] | ğŸ”´ High |
| [Theme 2] | [What this theme represents] | PP2, PP4 | [X]/[Total] | ğŸŸ¡ Medium |
| [Theme 3] | [What this theme represents] | PP6, PP7 | [X]/[Total] | ğŸŸ¢ Low |

---

## Theme Table: Detailed Analysis

| Theme | Evidence | Confidence | Implication |
|-------|----------|------------|-------------|
| [Theme name] | [X]/[Total] participants mentioned this; Quotes: "..." | ğŸ”´ High / ğŸŸ¡ Medium / ğŸŸ¢ Low | [What this means for product decisions] |
| [Theme name] | [...] | [...] | [...] |

**Confidence levels explained**:
- ğŸ”´ **High**: Mentioned by 60%+ participants with consistent evidence
- ğŸŸ¡ **Medium**: Mentioned by 30-60% participants or mixed evidence
- ğŸŸ¢ **Low**: Mentioned by <30% participants or limited evidence

---

## Positive Findings *(What Worked Well)*

*Don't only focus on problems - highlight what users loved too!*

### What Users Appreciated

1. **[Positive aspect]**
   - Evidence: "[Quote from P##]" (timestamp)
   - Why it matters: [Impact on UX or business]

2. **[Positive aspect]**
   - Evidence: "[Quote]" (timestamp)
   - Why it matters: [...]

3. **[Positive aspect]**
   - Evidence: "[Quote]" (timestamp)
   - Why it matters: [...]

**Preserve these strengths**: [1 sentence on why these should be maintained in future iterations]

---

## Behavioral Patterns

*Observable user behaviors, not just what they said*

| Pattern | Description | Frequency | Implication |
|---------|-------------|-----------|-------------|
| [Pattern 1] | [What users consistently did] | [X]/[Total] participants | [What this means] |
| [Pattern 2] | [What users consistently did] | [X]/[Total] participants | [What this means] |

---

## Participant Overview *(Anonymized)*

**Total Participants**: [Number]

**Demographics** *(if relevant)*:
- Roles: [e.g., "5 Architects, 2 Engineers, 1 PM"]
- Experience levels: [e.g., "3 Novice, 3 Intermediate, 2 Expert"]
- Company sizes: [e.g., "4 Small firms (<50), 3 Medium (50-200), 1 Large (200+)"]
- Locations: [e.g., "5 North America, 2 Europe, 1 Asia"]

**Participant Profiles**:
| ID | Role | Experience | Usage Pattern | Notes |
|----|------|------------|---------------|-------|
| P01 | [Role - no company name] | [Years/level] | [e.g., "Churned user"] | [Any relevant context] |
| P02 | [...] | [...] | [...] | [...] |

---

## Recommendations *(Prioritized)*

*Actionable next steps for product, design, and research teams*

### ğŸ”´ High Priority (Do First)

**1. [Recommendation]**
- **Why**: [Rationale - frequency, severity, business impact]
- **Addresses**: Pain Point #[X]
- **Expected Impact**: [Outcome if implemented]
- **Suggested Owner**: [Team/person]

**2. [Recommendation]**
- **Why**: [...]
- **Addresses**: Pain Point #[X]
- **Expected Impact**: [...]
- **Suggested Owner**: [...]

### ğŸŸ¡ Medium Priority (Do Next)

**3. [Recommendation]**
- **Why**: [...]
- **Addresses**: Pain Point #[X]
- **Expected Impact**: [...]

**4. [Recommendation]**
- **Why**: [...]
- **Addresses**: Pain Point #[X]
- **Expected Impact**: [...]

### ğŸŸ¢ Low Priority (Nice to Have)

**5. [Recommendation]**
- **Why**: [...]
- **Addresses**: Pain Point #[X]
- **Expected Impact**: [...]

---

## What to Validate Next

*Open questions and suggested follow-up research*

### Unanswered Questions
- [Question that emerged but wasn't answered in this study]
- [Question about unexpected finding that needs more research]
- [Question about contradictory evidence]

### Suggested Follow-Up Research

**1. [Research topic]**
- **Why**: [Why this needs more research]
- **Method**: [Suggested methodology]
- **Timeline**: [When this should happen]

**2. [Research topic]**
- **Why**: [...]
- **Method**: [...]
- **Timeline**: [...]

---

## Limitations & Caveats

*Important context about the research*

### Sample Size
- Total participants: [Number]
- **Note**: [e.g., "Small sample size for qualitative research (5-8 typical). Findings represent patterns, not statistical significance."]

### Participant Diversity
- [Note any biases or gaps in participant pool]
- **Example**: "All participants were from North America - may not represent global users"

### Methodology Limitations
- [Note any methodological constraints]
- **Example**: "Remote sessions may not capture full context of in-person workflows"

### Confidence Levels
- Findings with ğŸ”´ High confidence: Based on [X]% of participants
- Findings with ğŸŸ¡ Medium confidence: Based on [X]% of participants
- Findings with ğŸŸ¢ Low confidence: Based on [X]% of participants

### What We Can't Conclude
- [Things this research does NOT tell us]
- [Avoid over-generalizing from qualitative data]

---

## Appendix: Raw Data Summary

### Session Notes
- See: `memory/session-notes/[project-name]/P01.md` through `P[##].md`

### Recordings
- Stored in: `memory/session-notes/[project-name]/`
- Format: P##-recording.[format]

### Transcripts
- Available: âœ… Yes / âŒ No
- Location: [If available]

---

## Methodology Recap

**Research Type**: [Interviews / Usability Tests / Surveys / Mixed]

**Participant Recruitment**: [How participants were sourced]

**Screening**: [How participants were screened - see screener document]

**Session Format**: [Duration, remote/in-person, tools used]

**Analysis Method**: [How findings were synthesized]

**Compliance**: âœ… All participants signed CRA | âœ… Recording consent obtained | âœ… PII anonymized

---

## Tags for Repository

*For searchability in the research repository*

- **OKRs**: [Which OKRs does this support?]
- **Teams**: [Which teams should care about these findings?]
- **Topics**: [churned-users], [onboarding], [collaboration], [feature-name], etc.
- **Product Areas**: [Which parts of product are affected?]

---

## Share Out Plan

*How and where these findings will be shared*

- [ ] **Report Created**: One-pager / Slide deck / Detailed report
- [ ] **Stakeholders Notified**: [List]
- [ ] **Presentation Scheduled**: [Date/meeting]
- [ ] **Slack Shared**: [Channel]
- [ ] **Filed in Repository**: [Location with tags]

---

_Findings synthesized by Autodesk Research Assistant Agent. All evidence extracted directly from participant transcripts (no hallucination). All participants anonymized._
