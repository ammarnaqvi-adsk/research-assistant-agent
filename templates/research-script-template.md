# [Project Name] Research Script

**Research Plan**: See `memory/research-plans/[project-name]-research-plan.md`

**Session Type**: [Interview / Usability Test / Hybrid]

**Duration**: [30 / 45 / 60] minutes

**Date Created**: [Date]

---

## Pre-Session Checklist

Before the session starts, ensure:
- [ ] Participant has signed CRA (Customer Research Agreement)
- [ ] Recording equipment/software is ready
- [ ] Screen-sharing is set up (if remote)
- [ ] Prototype/test materials are ready and accessible
- [ ] Backup facilitator or notetaker identified
- [ ] Observer instructions shared (if observers present)

---

## Script Structure

### 1. Introduction & Consent (5 minutes)

**Welcome participant warmly and build rapport**

> "Hi [Participant first name], thank you so much for joining us today! My name is [Your name], and I'm a [Your role] at Autodesk. How are you doing today?"

**Introduce the session**

> "Today we're going to [describe the session briefly - e.g., 'spend about an hour talking about your experience with [product]' or 'ask you to try out some tasks in our product while thinking aloud']."
>
> "The goal is to learn from you so we can improve [the product]. There are no wrong answers - we're testing the product, not you. Your honest feedback, whether positive or negative, is incredibly valuable."

**Confirm CRA and recording consent**

> "Before we signed the Customer Research Agreement, which allows us to use your feedback to improve our products. That's still all good, right?"

*[Wait for confirmation]*

> "Great. I'd also like to record this session so our team can review it later and make sure we don't miss anything important. The recording will only be used internally at Autodesk. Is that okay with you?"

*[Wait for explicit verbal consent - document this in notes]*

> "Thank you. Just to let you know, I'm starting the recording now."

*[Start recording]*

**Explain think-aloud protocol** (if usability test)

> "As you work through tasks today, I'm going to ask you to think aloud - that means saying out loud what you're thinking, what you're looking for, what's confusing, what you expect to happen. This helps us understand your thought process."
>
> "It might feel a bit awkward at first, but it's really helpful for us. I'll remind you if you go quiet!"

**Set expectations**

> "A few housekeeping items:
> - This session should take about [duration] minutes
> - Feel free to ask questions anytime, though I might not answer right away if I want to see how you figure things out
> - You can take a break anytime you need
> - If you want to stop at any point, just let me know - no problem at all
>
> Do you have any questions before we get started?"

---

### 2. Warm-Up Questions (5-10 minutes)

**Build rapport and gather context (use open-ended questions)**

**About the participant:**
- "Tell me a bit about yourself and what you do."
- "Walk me through a typical day or week in your role."
- [Add role-specific question based on screener]

**About their relationship with the product/topic:**
- "Have you used [product name] before?"
  - *If yes*: "What do you typically use it for?"
  - *If no*: "What tools do you currently use for [task/workflow]?"
- "How long have you been [doing X activity related to research]?"
- [Add context-specific question]

**Transition to main content:**
> "Great, thank you for that context. Now let's dive into [the main focus]."

---

### 3. Core Questions / Tasks (30-40 minutes)

*Choose ONE of the following formats based on methodology:*

---

#### Option A: Interview Format (for generative research)

**Research Goal 1: [Topic/Theme]**

*Map each section to a research goal from the research plan*

**Main Question** (open-ended, not leading):
- "[Question mapped to research goal]"
  - Example: "Tell me about the last time you [did X activity]."
  - Example: "Walk me through how you currently [solve this problem]."

**Follow-up Probes** (use as needed to dig deeper):
- "What made that [easy/difficult/frustrating]?"
- "How did you work around that?"
- "What would have made that better?"
- "Can you give me a specific example?"
- "How often does that happen?"
- "What did you expect to happen?"

**⚠️ Avoid leading questions:**
- ❌ Don't say: "Don't you think this is confusing?"
- ✅ Instead say: "What are your thoughts on this?"

---

**Research Goal 2: [Topic/Theme]**

**Main Question**:
- "[Question]"

**Follow-up Probes**:
- "[Probe question]"
- "[Probe question]"

---

**Research Goal 3: [Topic/Theme]**

**Main Question**:
- "[Question]"

**Follow-up Probes**:
- "[Probe question]"
- "[Probe question]"

---

#### Option B: Usability Test Format (for evaluative research)

**Task 1: [Task Name]**

**Instruction for participant (clear, non-leading):**
> "[Task instruction - e.g., 'Imagine you want to create a new project for a building site. Show me how you would do that.']"

**Success Criteria** (for facilitator - don't share with participant):
- [ ] Participant completes task without assistance
- [ ] Participant finds [key feature/button]
- [ ] Participant understands [concept]

**Follow-up Questions (after task):**
- "On a scale of 1-5, how easy or difficult was that task?" (1 = very difficult, 5 = very easy)
- "What, if anything, was confusing or frustrating?"
- "What did you expect to happen at [specific moment]?"
- "Is there anything you would have wanted to do differently?"

**Timestamp important moments:**
- Note any confusion, errors, or friction
- Note positive reactions or "aha" moments
- Capture exact quotes (for video clips later)

---

**Task 2: [Task Name]**

**Instruction for participant:**
> "[Task instruction]"

**Success Criteria:**
- [ ] [Criterion 1]
- [ ] [Criterion 2]

**Follow-up Questions:**
- "[Question]"
- "[Question]"

---

**Task 3: [Task Name]**

*[Repeat format for each task]*

---

### 4. Closing Questions (5 minutes)

**Wrap-up questions to capture overall impressions:**

1. "Overall, what do you think about [the product / the experience / what you tried today]?"

2. "If you could wave a magic wand and change one thing about [the product], what would it be?"
   - Follow-up: "Why is that important to you?"

3. "Is there anything that was particularly easy or worked really well for you?"

4. "Is there anything we didn't talk about today that you think is important for us to know?"

5. "Do you have any questions for me?"

---

### 5. Thank You & Wrap-Up (2 minutes)

**Express gratitude:**
> "Thank you so much for your time and feedback today. This has been incredibly helpful for our team."

**Explain next steps:**
> "We'll be talking to a few more people over the next [timeframe], and then we'll synthesize all the feedback to inform [what the research will impact - e.g., 'the next version of the product' or 'our roadmap priorities']."

**Confirm incentive** (if applicable):
> "You should receive your [incentive - e.g., gift card] within [timeframe]. If you don't see it by [date], feel free to reach out to [contact]."

**Final goodbye:**
> "Thanks again, and have a great rest of your day!"

*[Stop recording]*

---

## Post-Session Checklist

Immediately after the session:
- [ ] Stop recording and save file securely
- [ ] Document any technical issues or observer notes
- [ ] Assign participant ID (P01, P02, etc.) and remove real name from all files
- [ ] Save recording to `memory/session-notes/[project-name]/[participant-id]-recording`
- [ ] Export transcript (if available) to `memory/session-notes/[project-name]/[participant-id].md`
- [ ] Note any standout quotes with timestamps for video clips
- [ ] Update research plan schedule with completion status

---

## Facilitator Tips

### Do:
- ✅ **Listen more than you talk** - aim for 80/20 participant to facilitator
- ✅ **Ask open-ended questions** - start with "Tell me...", "Walk me through...", "How did you..."
- ✅ **Use silence** - pause after questions, let participant think
- ✅ **Probe for specifics** - "Can you give me an example?" "What happened next?"
- ✅ **Stay neutral** - don't defend the product or show disappointment
- ✅ **Capture exact quotes** - write them down verbatim with timestamps
- ✅ **Note non-verbal cues** - confusion, frustration, delight

### Don't:
- ❌ **Ask leading questions** - "Don't you think this is confusing?" → "What do you think about this?"
- ❌ **Explain how things work** - let participants figure it out (that's the point!)
- ❌ **Ask yes/no questions** - turn them into open-ended ones
- ❌ **Rush** - let participants take their time
- ❌ **Interrupt** - unless they're really stuck or going way off track
- ❌ **Make promises** - "We'll definitely add that feature" → "That's great feedback, thank you"

### If Participant Gets Stuck:
1. **First**: Use silence - give them 10-15 seconds to work it out
2. **Then**: Ask neutral questions - "What are you thinking right now?" "What are you looking for?"
3. **If still stuck**: Offer a small hint - "Have you tried looking in [general area]?"
4. **Last resort**: Show them, but note that they needed help

---

## Leading Questions to Avoid

**This script has been reviewed for leading questions. The following patterns were removed:**

| ❌ Leading (Bad) | ✅ Neutral (Good) |
|-----------------|------------------|
| "Don't you think this is confusing?" | "What are your thoughts on this?" |
| "How much do you love this feature?" | "What's your reaction to this feature?" |
| "This is hard to use, right?" | "How easy or difficult was that to use?" |
| "Wouldn't it be better if..." | "How could this be improved?" |
| "Do you like X or Y?" | "What do you think about X? And Y?" |

---

_Generated by Autodesk Research Assistant Agent. Reviewed for leading questions and Autodesk compliance._
